{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ae2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818db56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_messages: content='我喜欢编程。 (Wǒ xǐhuān biānchéng.)' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "c = chat.predict_messages([HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")])\n",
    "print(f\"predict_messages: {c}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6cb1059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0888782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5712f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f27c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nBrightToe Socks.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"What would be a good company name for a company that makes colorful socks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb160082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRainbow Toes Socks!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "592abf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.run(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7db56b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"  I'm sorry, I didn't understand that. Could you please rephrase your question?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"我想学习langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed9d54c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  确实，我可以用中文回答你的问题。你想学习什么语言？'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"please anwser question with chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d45137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"我想学习langchain，你有什么好的学习资料吗\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "811a4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"请给我列举一些好的学习网站或者书籍\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca56879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"非常感谢你的建议\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b96ff4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'   Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"你觉得langchain的优点有哪些\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d13f8fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'   是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36df29e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"Tell me a joke.\")\n",
    "no_input_prompt.format()\n",
    "# -> \"Tell me a joke.\"\n",
    "\n",
    "# An example prompt with one input variable\n",
    "one_input_prompt = PromptTemplate(input_variables=[\"adjective\"], template=\"Tell me a {adjective} joke.\")\n",
    "one_input_prompt.format(adjective=\"funny\")\n",
    "# -> \"Tell me a funny joke.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9fc2560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example prompt with multiple input variables\n",
    "multiple_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"], \n",
    "    template=\"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "multiple_input_prompt.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "416b570b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template.input_variables\n",
    "# -> ['adjective', 'content']\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "# -> Tell me a funny joke about chickens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c4204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'   中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"请给我详细讲一讲中国的关羽\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "007ca225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'   得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"继续\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ea5b9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"为什么一次回答的字数这么少呢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3d09bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"你每次回答的长度是多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c62a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"为什么没有回答完整就结束了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f623898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:     我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。\n",
      "Human: 请用langchain写个链式调用的Demo\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    确实，我可以给你写一个用langchain写的链式调用的Demo。首先，我们需要定义一个函数，用于实现链式调用：\\n\\ndef chain_call(func):\\n    def wrapper(*args, **kwargs):\\n        result = func(*args, **kwargs)\\n        return chain_call(result)\\n    return wrapper\\n\\n然后，我们可以定义一些函数，用于实现链式调用：\\n\\n@chain_call\\ndef add(x, y):\\n    return x + y\\n\\n@chain_call\\ndef subtract(x, y):\\n    return x - y\\n\\n@chain_call\\ndef multiply(x, y):\\n    return x *'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"请用langchain写个链式调用的Demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06386979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:     我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。\n",
      "Human: 请用langchain写个链式调用的Demo\n",
      "AI:     确实，我可以给你写一个用langchain写的链式调用的Demo。首先，我们需要定义一个函数，用于实现链式调用：\n",
      "\n",
      "def chain_call(func):\n",
      "    def wrapper(*args, **kwargs):\n",
      "        result = func(*args, **kwargs)\n",
      "        return chain_call(result)\n",
      "    return wrapper\n",
      "\n",
      "然后，我们可以定义一些函数，用于实现链式调用：\n",
      "\n",
      "@chain_call\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "@chain_call\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "\n",
      "@chain_call\n",
      "def multiply(x, y):\n",
      "    return x *\n",
      "Human: 请用langchain框架写个使用demo\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    确实，我可以给你写一个使用langchain框架的demo。首先，我们需要安装langchain框架，可以使用pip或者其他安装工具：\\n\\npip install langchain\\n\\n然后，我们可以创建一个新的项目：\\n\\nlangchain new my_project\\n\\n接下来，我们可以在项目中创建一个新的文件，用于编写代码：\\n\\ntouch my_project/main.py\\n\\n最后，我们可以在文件中编写代码，'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"请用langchain框架写个使用demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63e74147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:     我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。\n",
      "Human: 请用langchain写个链式调用的Demo\n",
      "AI:     确实，我可以给你写一个用langchain写的链式调用的Demo。首先，我们需要定义一个函数，用于实现链式调用：\n",
      "\n",
      "def chain_call(func):\n",
      "    def wrapper(*args, **kwargs):\n",
      "        result = func(*args, **kwargs)\n",
      "        return chain_call(result)\n",
      "    return wrapper\n",
      "\n",
      "然后，我们可以定义一些函数，用于实现链式调用：\n",
      "\n",
      "@chain_call\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "@chain_call\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "\n",
      "@chain_call\n",
      "def multiply(x, y):\n",
      "    return x *\n",
      "Human: 请用langchain框架写个使用demo\n",
      "AI:     确实，我可以给你写一个使用langchain框架的demo。首先，我们需要安装langchain框架，可以使用pip或者其他安装工具：\n",
      "\n",
      "pip install langchain\n",
      "\n",
      "然后，我们可以创建一个新的项目：\n",
      "\n",
      "langchain new my_project\n",
      "\n",
      "接下来，我们可以在项目中创建一个新的文件，用于编写代码：\n",
      "\n",
      "touch my_project/main.py\n",
      "\n",
      "最后，我们可以在文件中编写代码，\n",
      "Human: 继续\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"    例如，我们可以使用langchain框架来实现一个简单的计算器：\\n\\nfrom langchain import *\\n\\n@chain\\ndef calculator(x, y):\\n    return add(x, y), subtract(x, y), multiply(x, y)\\n\\nif __name__ == '__main__':\\n    x = 10\\n    y = 5\\n    result = calculator(x, y)\\n    print(result)\\n\\n运行结果为：(15, 5, 50)\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"继续\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f13542be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:     我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。\n",
      "Human: 请用langchain写个链式调用的Demo\n",
      "AI:     确实，我可以给你写一个用langchain写的链式调用的Demo。首先，我们需要定义一个函数，用于实现链式调用：\n",
      "\n",
      "def chain_call(func):\n",
      "    def wrapper(*args, **kwargs):\n",
      "        result = func(*args, **kwargs)\n",
      "        return chain_call(result)\n",
      "    return wrapper\n",
      "\n",
      "然后，我们可以定义一些函数，用于实现链式调用：\n",
      "\n",
      "@chain_call\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "@chain_call\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "\n",
      "@chain_call\n",
      "def multiply(x, y):\n",
      "    return x *\n",
      "Human: 请用langchain框架写个使用demo\n",
      "AI:     确实，我可以给你写一个使用langchain框架的demo。首先，我们需要安装langchain框架，可以使用pip或者其他安装工具：\n",
      "\n",
      "pip install langchain\n",
      "\n",
      "然后，我们可以创建一个新的项目：\n",
      "\n",
      "langchain new my_project\n",
      "\n",
      "接下来，我们可以在项目中创建一个新的文件，用于编写代码：\n",
      "\n",
      "touch my_project/main.py\n",
      "\n",
      "最后，我们可以在文件中编写代码，\n",
      "Human: 继续\n",
      "AI:     例如，我们可以使用langchain框架来实现一个简单的计算器：\n",
      "\n",
      "from langchain import *\n",
      "\n",
      "@chain\n",
      "def calculator(x, y):\n",
      "    return add(x, y), subtract(x, y), multiply(x, y)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    x = 10\n",
      "    y = 5\n",
      "    result = calculator(x, y)\n",
      "    print(result)\n",
      "\n",
      "运行结果为：(15, 5, 50)\n",
      "Human: 继续\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'     如果我们想要添加一个除法函数，我们可以在代码中添加一个新的函数：\\n\\n@chain\\ndef divide(x, y):\\n    return x / y\\n\\n然后，我们可以在calculator函数中添加一个新的参数：\\n\\n@chain\\ndef calculator(x, y):\\n    return add(x, y), subtract(x, y), multiply(x, y), divide(x, y)\\n\\n最后，我们可以运行程序，查看结果：\\n\\n(15, 5, 50, 2.0)'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"继续\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd44ffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:     我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。\n",
      "Human: 请用langchain写个链式调用的Demo\n",
      "AI:     确实，我可以给你写一个用langchain写的链式调用的Demo。首先，我们需要定义一个函数，用于实现链式调用：\n",
      "\n",
      "def chain_call(func):\n",
      "    def wrapper(*args, **kwargs):\n",
      "        result = func(*args, **kwargs)\n",
      "        return chain_call(result)\n",
      "    return wrapper\n",
      "\n",
      "然后，我们可以定义一些函数，用于实现链式调用：\n",
      "\n",
      "@chain_call\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "@chain_call\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "\n",
      "@chain_call\n",
      "def multiply(x, y):\n",
      "    return x *\n",
      "Human: 请用langchain框架写个使用demo\n",
      "AI:     确实，我可以给你写一个使用langchain框架的demo。首先，我们需要安装langchain框架，可以使用pip或者其他安装工具：\n",
      "\n",
      "pip install langchain\n",
      "\n",
      "然后，我们可以创建一个新的项目：\n",
      "\n",
      "langchain new my_project\n",
      "\n",
      "接下来，我们可以在项目中创建一个新的文件，用于编写代码：\n",
      "\n",
      "touch my_project/main.py\n",
      "\n",
      "最后，我们可以在文件中编写代码，\n",
      "Human: 继续\n",
      "AI:     例如，我们可以使用langchain框架来实现一个简单的计算器：\n",
      "\n",
      "from langchain import *\n",
      "\n",
      "@chain\n",
      "def calculator(x, y):\n",
      "    return add(x, y), subtract(x, y), multiply(x, y)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    x = 10\n",
      "    y = 5\n",
      "    result = calculator(x, y)\n",
      "    print(result)\n",
      "\n",
      "运行结果为：(15, 5, 50)\n",
      "Human: 继续\n",
      "AI:      如果我们想要添加一个除法函数，我们可以在代码中添加一个新的函数：\n",
      "\n",
      "@chain\n",
      "def divide(x, y):\n",
      "    return x / y\n",
      "\n",
      "然后，我们可以在calculator函数中添加一个新的参数：\n",
      "\n",
      "@chain\n",
      "def calculator(x, y):\n",
      "    return add(x, y), subtract(x, y), multiply(x, y), divide(x, y)\n",
      "\n",
      "最后，我们可以运行程序，查看结果：\n",
      "\n",
      "(15, 5, 50, 2.0)\n",
      "Human: 继续，请回答完整\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'     这就是使用langchain框架实现一个简单的计算器的完整过程。我们可以使用langchain框架来实现更复杂的应用程序，例如分布式应用程序、智能合约等。'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"继续，请回答完整\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6312732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: 我想学习langchain\n",
      "AI:  Sure, I can help you learn langchain. What language are you interested in learning?\n",
      "Human: 我想学习langchain\n",
      "AI:   I'm sorry, I didn't understand that. Could you please rephrase your question?\n",
      "Human: please anwser question with chinese\n",
      "AI:   确实，我可以用中文回答你的问题。你想学习什么语言？\n",
      "Human: 我想学习langchain，你有什么好的学习资料吗\n",
      "AI:   是的，我有一些关于langchain的学习资料。你可以在网上搜索一些教程，也可以参加一些在线课程。你可以在社交媒体上加入一些langchain的学习小组，也可以参加一些实体课程。\n",
      "Human: 请给我列举一些好的学习网站或者书籍\n",
      "AI:   好的，我可以给你列举一些关于langchain的学习网站或书籍。你可以在网上搜索Langchain官方网站，它提供了很多有用的资源。此外，你还可以参考《Langchain入门指南》、《Langchain实战指南》和《Langchain高级指南》等书籍。\n",
      "Human: 非常感谢你的建议\n",
      "AI:   不客气！我很高兴能帮助你。如果你有任何其他问题，请随时告诉我，我会尽力帮助你。\n",
      "Human: 你觉得langchain的优点有哪些\n",
      "AI:    Langchain有很多优点，其中一些是它的安全性、可扩展性、可靠性和可信性。它还提供了一个可靠的网络，可以让用户安全地进行交易。此外，它还提供了一个可扩展的架构，可以支持大量的交易。它还提供了一个可靠的系统，可以确保交易的可信性。\n",
      "Human: langchain不是一个LLMs的软件开发框架吗 为什么会有大量交易呢\n",
      "AI:    是的，Langchain是一个LLMs的软件开发框架。它提供了一个可扩展的架构，可以支持大量的交易。它可以帮助开发者快速开发和部署分布式应用程序，并且可以支持大量的交易。它还提供了一个安全的网络，可以让用户安全地进行交易。\n",
      "Human: 请给我详细讲一讲中国的关羽\n",
      "AI:    中国古代传奇人物关羽是三国时期著名的蜀汉将军，他是蜀汉的主要军事领袖之一。他出生于蜀汉的荆州，他的父亲是蜀汉的著名将领关平。他从小就展现出超凡的武艺，他曾参加过许多战役，并取得了许多胜利。他最著名的战役是赤壁之战，他在这场战役中击败了曹操的大军，取\n",
      "Human: 继续\n",
      "AI:    得了著名的胜利。他还参加了许多其他的战役，如官渡之战、襄阳之战等，并取得了许多胜利。他的勇敢和军事才能使他成为蜀汉的英雄，他也被称为“五虎将军”之一。\n",
      "Human: 为什么一次回答的字数这么少呢\n",
      "AI:     我的回答字数取决于你提出的问题的复杂程度。如果你提出的问题比较复杂，我可能需要更多的时间来回答，因此我的回答字数也会更多。\n",
      "Human: 你每次回答的长度是多少\n",
      "AI:     我每次回答的长度取决于你提出的问题的复杂程度。我会尽力回答你的问题，但是我的回答长度可能会有所不同。\n",
      "Human: 为什么没有回答完整就结束了\n",
      "AI:     我会尽力回答你的问题，但是如果我的回答涉及到比较复杂的内容，我可能需要更多的时间来回答，因此我的回答可能会有所不同。\n",
      "Human: 请用langchain写个链式调用的Demo\n",
      "AI:     确实，我可以给你写一个用langchain写的链式调用的Demo。首先，我们需要定义一个函数，用于实现链式调用：\n",
      "\n",
      "def chain_call(func):\n",
      "    def wrapper(*args, **kwargs):\n",
      "        result = func(*args, **kwargs)\n",
      "        return chain_call(result)\n",
      "    return wrapper\n",
      "\n",
      "然后，我们可以定义一些函数，用于实现链式调用：\n",
      "\n",
      "@chain_call\n",
      "def add(x, y):\n",
      "    return x + y\n",
      "\n",
      "@chain_call\n",
      "def subtract(x, y):\n",
      "    return x - y\n",
      "\n",
      "@chain_call\n",
      "def multiply(x, y):\n",
      "    return x *\n",
      "Human: 请用langchain框架写个使用demo\n",
      "AI:     确实，我可以给你写一个使用langchain框架的demo。首先，我们需要安装langchain框架，可以使用pip或者其他安装工具：\n",
      "\n",
      "pip install langchain\n",
      "\n",
      "然后，我们可以创建一个新的项目：\n",
      "\n",
      "langchain new my_project\n",
      "\n",
      "接下来，我们可以在项目中创建一个新的文件，用于编写代码：\n",
      "\n",
      "touch my_project/main.py\n",
      "\n",
      "最后，我们可以在文件中编写代码，\n",
      "Human: 继续\n",
      "AI:     例如，我们可以使用langchain框架来实现一个简单的计算器：\n",
      "\n",
      "from langchain import *\n",
      "\n",
      "@chain\n",
      "def calculator(x, y):\n",
      "    return add(x, y), subtract(x, y), multiply(x, y)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    x = 10\n",
      "    y = 5\n",
      "    result = calculator(x, y)\n",
      "    print(result)\n",
      "\n",
      "运行结果为：(15, 5, 50)\n",
      "Human: 继续\n",
      "AI:      如果我们想要添加一个除法函数，我们可以在代码中添加一个新的函数：\n",
      "\n",
      "@chain\n",
      "def divide(x, y):\n",
      "    return x / y\n",
      "\n",
      "然后，我们可以在calculator函数中添加一个新的参数：\n",
      "\n",
      "@chain\n",
      "def calculator(x, y):\n",
      "    return add(x, y), subtract(x, y), multiply(x, y), divide(x, y)\n",
      "\n",
      "最后，我们可以运行程序，查看结果：\n",
      "\n",
      "(15, 5, 50, 2.0)\n",
      "Human: 继续，请回答完整\n",
      "AI:      这就是使用langchain框架实现一个简单的计算器的完整过程。我们可以使用langchain框架来实现更复杂的应用程序，例如分布式应用程序、智能合约等。\n",
      "Human: 请实现一个智能合约\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'     确实，我可以给你实现一个智能合约。首先，我们需要定义一个智能合约，用于实现智能合约的功能：\\n\\ncontract MyContract {\\n    function myFunction(uint x, uint y) public returns (uint z) {\\n        z = x + y;\\n        return z;\\n    }\\n}\\n\\n然后，我们可以使用langchain框架来部署智能合约：\\n\\nlangchain deploy MyContract\\n\\n最后，我们可以使用langchain框架来调用智能合约：\\n\\nlangchain call MyContract'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"请实现一个智能合约\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c528ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = '     确实，我可以给你实现一个智能合约。首先，我们需要定义一个智能合约，用于实现智能合约的功能：\\n\\ncontract MyContract {\\n    function myFunction(uint x, uint y) public returns (uint z) {\\n        z = x + y;\\n        return z;\\n    }\\n}\\n\\n然后，我们可以使用langchain框架来部署智能合约：\\n\\nlangchain deploy MyContract\\n\\n最后，我们可以使用langchain框架来调用智能合约：\\n\\nlangchain call MyContract'\n",
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f37864a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = '     如果我们想要添加一个除法函数，我们可以在代码中添加一个新的函数：\\n\\n@chain\\ndef divide(x, y):\\n    return x / y\\n\\n然后，我们可以在calculator函数中添加一个新的参数：\\n\\n@chain\\ndef calculator(x, y):\\n    return add(x, y), subtract(x, y), multiply(x, y), divide(x, y)\\n\\n最后，我们可以运行程序，查看结果：\\n\\n(15, 5, 50, 2.0)'\n",
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c9bb9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: tiktoken in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e32a0ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf755280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 1609, 5963, 374, 2294, 0]\n"
     ]
    }
   ],
   "source": [
    "tik = encoding.encode(\"tiktoken is great!\")\n",
    "print(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "651ed789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str=\"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c381264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "716f103b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6fd50f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7319e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257, 82363, 98739, 33565, 111, 31634, 43955, 48044, 21418, 25333, 33904, 3922, 98739, 74770, 19000, 47200, 16325, 43955, 48044, 17039, 9554, 33904, 49543, 31, 8995, 198, 755, 22497, 2120, 11, 379, 997, 262, 471, 865, 611, 379, 271, 61994, 34547, 3922, 98739, 74770, 19000, 89921, 33904, 16325, 43955, 48044, 17039, 9554, 33765, 49543, 31, 8995, 198, 755, 31052, 2120, 11, 379, 997, 262, 471, 923, 2120, 11, 379, 705, 33356, 2120, 11, 379, 705, 31370, 2120, 11, 379, 705, 22497, 2120, 11, 379, 696, 32335, 34547, 3922, 98739, 74770, 91940, 23039, 75320, 3922, 33976, 52030, 60251, 49543, 7, 868, 11, 220, 20, 11, 220, 1135, 11, 220, 17, 13, 15, 8]\n"
     ]
    }
   ],
   "source": [
    "en_ss = encoding.encode(ss)\n",
    "print(en_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e284b6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b't', b'ik', b'token', b' is', b' great', b'!']\n"
     ]
    }
   ],
   "source": [
    "tik_b = [encoding.decode_single_token_bytes(token) for token in tik]\n",
    "print(tik_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33c8cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: unstructured in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (0.7.11)\n",
      "Requirement already satisfied: pdf2image in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (1.16.3)\n",
      "Requirement already satisfied: pdfminer.six in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (20221105)\n",
      "Requirement already satisfied: pandas in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (1.5.3)\n",
      "Requirement already satisfied: requests in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: openpyxl in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (3.1.2)\n",
      "Requirement already satisfied: xlrd in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (2.0.1)\n",
      "Requirement already satisfied: filetype in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: msg-parser in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: markdown in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: pillow in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (9.5.0)\n",
      "Requirement already satisfied: python-pptx in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: chardet in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: pypandoc in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: lxml in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: argilla in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (1.12.0)\n",
      "Requirement already satisfied: python-docx in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: tabulate in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: python-magic in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: nltk in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: backoff in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (2.2.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.6.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (0.7.0)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (1.2.14)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (1.10.9)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (0.23.3)\n",
      "Requirement already satisfied: rich<=13.0.1 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (13.0.1)\n",
      "Requirement already satisfied: numpy<1.24.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (4.65.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (1.14.1)\n",
      "Requirement already satisfied: monotonic in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (1.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from argilla->unstructured) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from pandas->unstructured) (2023.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from markdown->unstructured) (6.7.0)\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from msg-parser->unstructured) (0.46)\n",
      "Requirement already satisfied: joblib in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from nltk->unstructured) (1.3.1)\n",
      "Requirement already satisfied: click in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from nltk->unstructured) (2023.6.3)\n",
      "Requirement already satisfied: et-xmlfile in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from pdfminer.six->unstructured) (41.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from pdfminer.six->unstructured) (3.1.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from python-pptx->unstructured) (3.1.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests->unstructured) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests->unstructured) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
      "Requirement already satisfied: sniffio in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown->unstructured) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from pydantic>=1.10.7->argilla->unstructured) (4.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from rich<=13.0.1->argilla->unstructured) (2.15.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycparser in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.7.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/bing/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "222e9954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bing/code/example_py3'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca7a9687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 1609, 5963, 374, 2294, 0, 259, 13665, 374, 4037]\n"
     ]
    }
   ],
   "source": [
    "tik = encoding.encode(\"tiktoken is great! t ik is token\")\n",
    "print(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea4d1246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b't', b'ik', b'token', b' is', b' great', b'!', b' t', b' ik', b' is', b' token']\n"
     ]
    }
   ],
   "source": [
    "tik_b = [encoding.decode_single_token_bytes(token) for token in tik]\n",
    "print(tik_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f98c34e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 1609, 5963, 374, 2294, 0, 87272, 380, 1713, 6127, 1713, 1609]\n"
     ]
    }
   ],
   "source": [
    "tik = encoding.encode(\"tiktoken is great! tikistoken istokenik\")\n",
    "print(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d3450a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b't', b'ik', b'token', b' is', b' great', b'!', b' tik', b'ist', b'oken', b' ist', b'oken', b'ik']\n"
     ]
    }
   ],
   "source": [
    "tik_b = [encoding.decode_single_token_bytes(token) for token in tik]\n",
    "print(tik_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf455938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=0), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3267f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.save(\"llm_chain.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37378416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"memory\": null,\r\n",
      "    \"verbose\": true,\r\n",
      "    \"tags\": null,\r\n",
      "    \"prompt\": {\r\n",
      "        \"input_variables\": [\r\n",
      "            \"question\"\r\n",
      "        ],\r\n",
      "        \"output_parser\": null,\r\n",
      "        \"partial_variables\": {},\r\n",
      "        \"template\": \"Question: {question}\\n\\nAnswer: Let's think step by step.\",\r\n",
      "        \"template_format\": \"f-string\",\r\n",
      "        \"validate_template\": true,\r\n",
      "        \"_type\": \"prompt\"\r\n",
      "    },\r\n",
      "    \"llm\": {\r\n",
      "        \"model_name\": \"text-davinci-003\",\r\n",
      "        \"temperature\": 0.0,\r\n",
      "        \"max_tokens\": 256,\r\n",
      "        \"top_p\": 1,\r\n",
      "        \"frequency_penalty\": 0,\r\n",
      "        \"presence_penalty\": 0,\r\n",
      "        \"n\": 1,\r\n",
      "        \"request_timeout\": null,\r\n",
      "        \"logit_bias\": {},\r\n",
      "        \"_type\": \"openai\"\r\n",
      "    },\r\n",
      "    \"output_key\": \"text\",\r\n",
      "    \"output_parser\": {\r\n",
      "        \"_type\": \"default\"\r\n",
      "    },\r\n",
      "    \"return_final_only\": true,\r\n",
      "    \"llm_kwargs\": {},\r\n",
      "    \"_type\": \"llm_chain\"\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "cat llm_chain.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fc78c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import load_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88d15f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_chain(\"llm_chain.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9757d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: whats 2 + 2\n",
      "\n",
      "Answer: Let's think step by step.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 2 + 2 = 4'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"whats 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a83b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ccf7bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[1;32m      7\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m      8\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(prompt_template)\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mllm_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolorful socks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    168\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    169\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    154\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    155\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    156\u001b[0m     inputs,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/llm.py:92\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     90\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 92\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/llm.py:102\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:141\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    135\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    140\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:227\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         )\n\u001b[1;32m    224\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    225\u001b[0m         dumpd(\u001b[38;5;28mself\u001b[39m), prompts, invocation_params\u001b[38;5;241m=\u001b[39mparams, options\u001b[38;5;241m=\u001b[39moptions\n\u001b[1;32m    226\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:178\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    177\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    179\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:165\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    157\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    162\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 165\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/openai.py:336\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     choices\u001b[38;5;241m.\u001b[39mextend(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     choices\u001b[38;5;241m.\u001b[39mextend(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")\n",
    "llm_chain(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32077b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n\\nCozy Toes Socks.'},\n",
       " {'text': '\\n\\nTechCore Solutions.'},\n",
       " {'text': '\\n\\nFootwear Factory.'}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"product\": \"socks\"},\n",
    "    {\"product\": \"computer\"},\n",
    "    {\"product\": \"shoes\"}\n",
    "]\n",
    "\n",
    "llm_chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ceada986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate与 类似apply，只不过它返回一个LLMResult而不是字符串。LLMResult通常包含有用的生成，例如令牌用法和完成原因。\n",
    "ll_g = llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bae7238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\nSocktastic!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nTechCore Solutions.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nFootwear Factory.', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 36, 'total_tokens': 55, 'completion_tokens': 19}, 'model_name': 'text-davinci-003'} run=[RunInfo(run_id=UUID('c371b48e-b26f-439d-b26a-400412d695b7')), RunInfo(run_id=UUID('1b2e9679-0b3d-4ee1-b395-d2655ef2fd1f')), RunInfo(run_id=UUID('dac340fc-ff22-4401-bd31-18a452a594e1'))]\n"
     ]
    }
   ],
   "source": [
    "print(ll_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9168edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='\\n\\nSocktastic!' generation_info={'finish_reason': 'stop', 'logprobs': None}\n",
      "text='\\n\\nTechCore Solutions.' generation_info={'finish_reason': 'stop', 'logprobs': None}\n",
      "text='\\n\\nFootwear Factory.' generation_info={'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "for g in ll_g.generations:\n",
    "    print(g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ddb2e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict与方法类似run，只是输入键被指定为关键字参数而不是 Python 字典\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "881b8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
    "\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "704e56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
    "\n",
    "Play Synopsis:\n",
    "{synopsis}\n",
    "Review from a New York Times play critic of the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af17b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d2edaa07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4639cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised RateLimitError: You exceeded your current quota, please check your plan and billing details..\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m review \u001b[38;5;241m=\u001b[39m \u001b[43moverall_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTragedy at sunset on the beach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:290\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m[_output_key]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags)[_output_key]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    168\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    169\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    154\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    155\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    156\u001b[0m     inputs,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/sequential.py:177\u001b[0m, in \u001b[0;36mSimpleSequentialChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    175\u001b[0m color_mapping \u001b[38;5;241m=\u001b[39m get_color_mapping([\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains))])\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chain \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains):\n\u001b[0;32m--> 177\u001b[0m     _input \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_outputs:\n\u001b[1;32m    179\u001b[0m         _input \u001b[38;5;241m=\u001b[39m _input\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:290\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m[_output_key]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags)[_output_key]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    168\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    169\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    154\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    155\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    156\u001b[0m     inputs,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/llm.py:92\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     90\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 92\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/chains/llm.py:102\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m prompts, stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_prompts(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:141\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    135\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    140\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:227\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m         )\n\u001b[1;32m    224\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    225\u001b[0m         dumpd(\u001b[38;5;28mself\u001b[39m), prompts, invocation_params\u001b[38;5;241m=\u001b[39mparams, options\u001b[38;5;241m=\u001b[39moptions\n\u001b[1;32m    226\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:178\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    177\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    179\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/base.py:165\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    157\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    162\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 165\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/openai.py:336\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     choices\u001b[38;5;241m.\u001b[39mextend(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     choices\u001b[38;5;241m.\u001b[39mextend(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/langchain/llms/openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_hw/lib/python3.9/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Tragedy at sunset on the beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a17df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\", 111))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d885f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "beefa96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='whats up?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb07da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
